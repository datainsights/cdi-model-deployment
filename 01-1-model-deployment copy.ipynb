{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284be38c",
   "metadata": {},
   "source": [
    "# (PART) EDA {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b24328",
   "metadata": {},
   "source": [
    "# How do you read the dataset from the `data/` folder before deployment?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Before deploying any machine learning model, it's essential to understand the data it was trained on. This step helps ensure consistent preprocessing, reproducibility, and seamless integration across tools.\n",
    "\n",
    "In the CDI deployment pipeline, we assume that cleaned and prepared data (like Titanic or Iris datasets) is stored in a `data/` folder at the project root. This structure allows for organized workflows and compatibility with scripts and APIs.\n",
    "\n",
    "We'll demonstrate how to read a typical dataset using both **Python** and **R**, preparing it for evaluation or serving.\n",
    "\n",
    "## Python Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81da93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "\n",
    "# Preview the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f265d",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "library(readr)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df <- read_csv(\"data/titanic.csv\")\n",
    "\n",
    "# Preview the first few rows\n",
    "head(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b499c1",
   "metadata": {},
   "source": [
    "> ✅ Takeaway: Store your datasets in a consistent data/ directory and load them early to ensure your models, APIs, and frontends share the same input structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1ebb8",
   "metadata": {},
   "source": [
    "# How do you train and save multiple models for deployment?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Once your dataset is loaded and preprocessed, the next step in the deployment pipeline is to train machine learning models and save them for reuse. Saving models allows you to:\n",
    "\n",
    "- Avoid retraining every time the API is restarted\n",
    "- Load models instantly in production\n",
    "- Maintain version control and reproducibility\n",
    "\n",
    "In this example, we’ll use the Titanic dataset and train multiple classification models. We'll then save each model as a `.joblib` file into a `models/` folder for future deployment.\n",
    "\n",
    "## Python Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47234ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripts/train_n_save_models.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import joblib\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"data/titanic.csv\")\n",
    "df.dropna(subset=[\"Age\", \"Fare\", \"Embarked\", \"Sex\", \"Survived\"], inplace=True)\n",
    "df[\"Sex\"] = df[\"Sex\"].astype(\"category\").cat.codes\n",
    "df[\"Embarked\"] = df[\"Embarked\"].astype(\"category\").cat.codes\n",
    "\n",
    "X = df[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"]]\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models to train\n",
    "models = {\n",
    "    \"logistic_regression\": LogisticRegression(max_iter=200),\n",
    "    \"random_forest\": RandomForestClassifier(),\n",
    "    \"gradient_boosting\": GradientBoostingClassifier(),\n",
    "    \"svc\": SVC(probability=True),\n",
    "    \"decision_tree\": DecisionTreeClassifier(),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"naive_bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Ensure models directory exists\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Train and save each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, f\"models/{name}.joblib\")\n",
    "    print(f\"✅ Saved: models/{name}.joblib\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf883e",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# R version not included in this example as the deployment focus uses joblib (.joblib) in Python.\n",
    "# Alternative: Save R models using saveRDS() if needed for Shiny APIs.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742784d",
   "metadata": {},
   "source": [
    "> ✅ Takeaway: Save each trained model in a dedicated models/ folder using a consistent naming scheme. This enables fast, reliable deployment via your API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6658aa5",
   "metadata": {},
   "source": [
    "# How do you evaluate models before deployment?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Before deploying machine learning models, it's important to evaluate their performance on **unseen test data**. This helps you:\n",
    "\n",
    "- Compare models based on accuracy, precision, recall, and F1 score\n",
    "- Select the best model(s) for deployment\n",
    "- Detect overfitting or underfitting\n",
    "- Create a summary table for documentation or reporting\n",
    "\n",
    "In this Q&A, we load previously saved models from the `models/` folder, evaluate them on test data, and store the results in a single CSV file: `evaluation_summary.csv`.\n",
    "\n",
    "## Python Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "269273bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Evaluation summary saved to: data/evaluation_summary.csv see results below:\n",
      "\n",
      "                 Model  Accuracy  Precision  Recall  F1 Score\n",
      "0                  knn    0.6853     0.6841  0.6867    0.6838\n",
      "1                  svc    0.6364     0.6378  0.6109    0.6038\n",
      "2  logistic_regression    0.7902     0.8057  0.7737    0.7784\n",
      "3    gradient_boosting    0.7832     0.7917  0.7691    0.7732\n",
      "4        random_forest    0.7832     0.7837  0.7742    0.7769\n",
      "5          naive_bayes    0.7692     0.7734  0.7566    0.7600\n",
      "6        decision_tree    0.6853     0.6816  0.6732    0.6746\n"
     ]
    }
   ],
   "source": [
    "# scripts/evaluate_models.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "MODEL_DIR = \"models\"\n",
    "DATA_PATH = \"data/titanic.csv\"\n",
    "OUTPUT_FILE = \"data/evaluation_summary.csv\"\n",
    "\n",
    "# Load and preprocess Titanic data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.dropna(subset=[\"Age\", \"Fare\", \"Embarked\", \"Sex\", \"Survived\"])\n",
    "df[\"Sex\"] = df[\"Sex\"].astype(\"category\").cat.codes\n",
    "df[\"Embarked\"] = df[\"Embarked\"].astype(\"category\").cat.codes\n",
    "df[\"Survived\"] = df[\"Survived\"].astype(int)\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"]\n",
    "X = df[features]\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Evaluate all saved models\n",
    "for filename in os.listdir(MODEL_DIR):\n",
    "    if filename.endswith(\".joblib\"):\n",
    "        model_path = os.path.join(MODEL_DIR, filename)\n",
    "        model = joblib.load(model_path)\n",
    "        model_name = filename.replace(\".joblib\", \"\")\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Use macro avg for simplicity\n",
    "        precision = report[\"macro avg\"][\"precision\"]\n",
    "        recall = report[\"macro avg\"][\"recall\"]\n",
    "        f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": round(acc, 4),\n",
    "            \"Precision\": round(precision, 4),\n",
    "            \"Recall\": round(recall, 4),\n",
    "            \"F1 Score\": round(f1, 4)\n",
    "        })\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\n✅ Evaluation summary saved to: {OUTPUT_FILE} see results below:\\n\")\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8c0d8",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# For a Python-based deployment workflow, use Python for evaluation.\n",
    "# For R-based workflows, use caret::confusionMatrix() or metrics from modelr or yardstick.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578138c7",
   "metadata": {},
   "source": [
    "> ✅ Takeaway: Always evaluate your models and store the results before deployment. This ensures you deploy with confidence and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196a659",
   "metadata": {},
   "source": [
    "# How do you serve saved models as prediction endpoints using FastAPI?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Once you've saved your trained models, the next step is to create an API that loads those models and makes them available for real-time prediction. FastAPI is a lightweight, high-performance framework that’s ideal for this.\n",
    "\n",
    "In this Q&A, we define a FastAPI app that:\n",
    "- Loads all `.joblib` models from the `models/` folder\n",
    "- Defines a prediction route `/predict/{model_name}`\n",
    "- Accepts JSON input using a `pydantic` schema\n",
    "- Returns a prediction as a JSON response\n",
    "\n",
    "## Python Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f1d84",
   "metadata": {},
   "source": [
    "```python\n",
    "# script/model_api.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load models dynamically\n",
    "MODEL_DIR = \"models\"\n",
    "models = {}\n",
    "\n",
    "for fname in os.listdir(MODEL_DIR):\n",
    "    if fname.endswith(\".joblib\"):\n",
    "        model_name = fname.replace(\".joblib\", \"\")\n",
    "        model_path = os.path.join(MODEL_DIR, fname)\n",
    "        models[model_name] = joblib.load(model_path)\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Define input schema\n",
    "class InputData(BaseModel):\n",
    "    Pclass: int\n",
    "    Sex: int\n",
    "    Age: float\n",
    "    Fare: float\n",
    "    Embarked: int\n",
    "\n",
    "# Define output schema\n",
    "class PredictionOutput(BaseModel):\n",
    "    model: str\n",
    "    prediction: int\n",
    "\n",
    "# Route to list available models\n",
    "@app.get(\"/models\")\n",
    "def list_models():\n",
    "    return {\"available_models\": list(models.keys())}\n",
    "\n",
    "# Route to predict using any loaded model\n",
    "@app.post(\"/predict/{model_name}\", response_model=PredictionOutput)\n",
    "def predict(model_name: str, input_data: InputData):\n",
    "    if model_name not in models:\n",
    "        raise HTTPException(status_code=404, detail=\"Model not found.\")\n",
    "\n",
    "    input_df = pd.DataFrame([input_data.dict()])\n",
    "    model = models[model_name]\n",
    "\n",
    "    try:\n",
    "        prediction = model.predict(input_df)[0]\n",
    "        return PredictionOutput(model=model_name, prediction=int(prediction))\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db5c81",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# This deployment workflow is implemented in Python using FastAPI.\n",
    "# For R, consider plumber for serving models as REST APIs.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b2373",
   "metadata": {},
   "source": [
    "> ✅ Takeaway: FastAPI allows you to create scalable prediction endpoints by loading saved models and exposing them through clean, documented routes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd33b10",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a058d6",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a2261c",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7252b",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc54c4b",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a593d5",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b12c2ea",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890ae97",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49f3b9",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7b822",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6423c37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0468819f",
   "metadata": {},
   "source": [
    "# (PART) VIZ {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314aa715",
   "metadata": {},
   "source": [
    "# (PART) STATS {-}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6712daf",
   "metadata": {},
   "source": [
    "# (PART) ML {-}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
